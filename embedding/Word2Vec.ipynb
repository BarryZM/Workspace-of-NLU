{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.hankcs.com/nlp/word2vec.html\n",
    "# https://zhuanlan.zhihu.com/p/53425736 cbow 多个词加权后在做输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "text = \"火星（Mars）是太阳系八大行星之一，是太阳系由内往外数的第四颗行星，属于类地行星，直径约为地球的53%，质量为地球的14%。自转轴倾角、自转周期均与地球相近，公转一周约为地球公转时间的两倍。橘红色外表是地表的赤铁矿（氧化铁）。我国古书上将火星称为“荧惑星”，西方古代（古罗马）称为“神话玛尔斯星”是十二星座白羊座的独一守护星，并非天蝎座的守护行星。火星基本上是沙漠行星，地表沙丘、砾石遍布且没有稳定的液态水体（2015年9月28日，美国宇航局公布火星上有少量的水。据法新社2018年7月25日报道，欧洲航天局(ESA)的研究员称，火星上发现了第一个液态地下水湖）。二氧化碳为主的大气既稀薄又寒冷，沙尘悬浮其中，每年常有尘暴发生。火星两极皆有水冰与干冰组成的极冠会随着季节消长。与地球相比，火星地质活动较不活跃，地表地貌大部分于远古较活跃的时期形成，有密布的陨石坑、火山与峡谷，包括太阳系最高的山：奥林帕斯山和最大的峡谷：水手号峡谷。另一个地形特征是南北半球的明显差别：南方是古老、充满陨石坑的高地，北方则是较年轻的平原。火星有两个天然卫星：火卫一和火卫二，形状不规则，可能是被隔离的矮小行星。在地球，火星肉眼可见，最高亮度可达-2.9等，八大行星中比木星、金星暗。2015年9月28日，美国航天局宣布火星存在流动水\"\n",
    "char_list = list(text)\n",
    "\n",
    "char_num = len(set(char_list))\n",
    "embedding_dim = 50\n",
    "windows_size = 4\n",
    "batch_size = 32 \n",
    "vocab_size = char_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_sample(input_list, window_size):\n",
    "    left_context = []\n",
    "    right_context = []\n",
    "    target = []\n",
    "    for idx, item in enumerate(input_list):\n",
    "        if idx+2*window_size+1 < len(input_list):\n",
    "#             print(input_list[idx:idx+window_size])\n",
    "            temp_left = input_list[idx:idx+window_size]\n",
    "            temp_right = input_list[idx+window_size+1:idx+2*window_size+1]\n",
    "            left_context.append(temp_left)\n",
    "            right_context.append(temp_right)\n",
    "            target.append(input_list[idx+window_size])\n",
    "    return left_context, right_context, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(char_list):\n",
    "    from numpy import array\n",
    "    from numpy import argmax\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(array(char_list))\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)   \n",
    "    return integer_encoded, onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(object):\n",
    "    def __init__(self):\n",
    "        self.w_1 = tf.Variable(tf.random_normal([vocab_size, embedding_dim], stddev=0.1), name='w_1')     \n",
    "        self.w_2 = tf.Variable(tf.random_normal([embedding_dim, vocab_size], stddev=0.1), name='w_2')\n",
    "        self.right = tf.placeholder(dtype=tf.float32, shape=[None, windows_size, vocab_size])\n",
    "        self.left = tf.placeholder(dtype=tf.float32, shape=[None, windows_size, vocab_size])\n",
    "        self.target = tf.placeholder(tf.float32, shape=[None, vocab_size])\n",
    "        self.cbow()\n",
    "\n",
    "    def cbow(self):\n",
    "        self.w_1 = tf.expand_dims(self.w_1, 0, name='w_1')\n",
    "#         self.w_2 = tf.expand_dims(self.w_2, 0, name='w_2')\n",
    "        self.w_1 = tf.tile(self.w_1, [batch_size, 1, 1], name='w_1_1')\n",
    "#         self.w_2 = tf.tile(self.w_2, [batch_size, 1, 1], name='w_2_1')\n",
    "        \n",
    "        left_encode = tf.matmul(self.left, self.w_1)\n",
    "        left_sum = tf.reduce_sum(left_encode, axis=1)\n",
    "        print(left_sum.get_shape())\n",
    "\n",
    "        right_encode = tf.matmul(self.right, self.w_1)\n",
    "        right_sum = tf.reduce_sum(right_encode, axis=1)\n",
    "        print(right_sum.get_shape())\n",
    "\n",
    "        context_encode = tf.concat([left_encode, right_encode], 1)\n",
    "        print(context_encode.get_shape())\n",
    "        context_sum = tf.reduce_sum(context_encode, axis=1)\n",
    "        print(context_sum.get_shape())\n",
    "\n",
    "#         context_sum = tf.expand_dims(context_sum, 0)\n",
    "#         context_sum = tf.tile(context_sum, [batch_size, 1, 1])\n",
    "        print(\"w2 shape\", self.w_2.get_shape())\n",
    "        outputs = tf.matmul(context_sum, self.w_2)\n",
    "        print(\"outputs shape\", outputs.get_shape())\n",
    "        \n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=self.target)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
    "        #self.trainer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Skip_Gram(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def skip_gram(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hoffman():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-7c6d7dd6df1e>:15: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "(32, 50)\n",
      "(32, 50)\n",
      "(32, 8, 50)\n",
      "(32, 50)\n",
      "w2 shape (50, 260)\n",
      "outputs shape (32, 260)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "integer_encoded, onehot_encoded = preprocessing(char_list)\n",
    "# print(\"integer encode\", integer_encoded[:3])\n",
    "# print(\"onehot_encoded\", onehot_encoded[:3])\n",
    "left_context, right_context, target = get_window_sample(onehot_encoded, windows_size)\n",
    "\n",
    "data_loader = tf.data.Dataset.from_tensor_slices(\n",
    "    {'left':np.asarray(left_context), \n",
    "     'right':np.asarray(right_context),\n",
    "     'target':np.asarray(target)})\n",
    "\n",
    "\n",
    "data_loader = data_loader.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))  #每个batch3个数据，不足3个舍弃\n",
    "iterator = data_loader.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "model = CBOW()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        sample_batched = sess.run(one_element)\n",
    "        left = sample_batched['left']\n",
    "#         print('left shape is', left.shape)\n",
    "        right = sample_batched['right']\n",
    "#         print('right shape is', right.shape)\n",
    "        target = sample_batched['target']\n",
    "#         print('target shape is', target.shape)\n",
    "        \n",
    "        outputs = sess.run(model.trainer,\n",
    "                           feed_dict = {model.left:left,\n",
    "                                        model.right:right,\n",
    "                                        model.target:target})\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n",
      "[1 2 3 1 2 3]\n",
      "[[1 2 3 1 2 3]]\n",
      "[[1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]\n",
      " [1 2 3 1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "temp = tf.tile([1,2,3],[2])\n",
    "temp1 = tf.expand_dims(temp, 0)\n",
    "print(tf.shape(temp1))\n",
    "temp2 = tf.tile(temp1, [32, 1])\n",
    "# temp2 = tf.tile([[1,2],[3,4],[5,6]],[2,3])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(temp))\n",
    "    print(sess.run(temp1))\n",
    "    print(sess.run(temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 迭代器\n",
    "# https://www.jianshu.com/p/5f9aca0a14fb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
