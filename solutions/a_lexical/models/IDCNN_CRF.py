# https://www.cnblogs.com/pinking/p/9192546.htmlimport tensorflow as tflayers = [            {                'dilation': 1            },            {                'dilation': 1            },            {                'dilation': 2            },        ]finalOutFromLayers = []totalWidthForLastDim = 0for j in range(4):    for i in range(len(layers)):        dilation =layers[i]['dilation']        isLast = True if i == (len(layers) - 1) else False        w = tf.get_variable("filterW",shape=[1, filter_width, num_filter,num_filter],initializer=tf.contrib.layers.xavier_initializer())        b = tf.get_variable("filterB", shape=[num_filter])        conv = tf.nn.atrous_conv2d(layerInput,w,rate=dilation,padding="SAME")        conv = tf.nn.bias_add(conv, b)        conv = tf.nn.relu(conv)        if isLast:            finalOutFromLayers.append(conv)            totalWidthForLastDim += num_filter        layerInput = convfinalOut = tf.concat(axis=3, values=finalOutFromLayers)