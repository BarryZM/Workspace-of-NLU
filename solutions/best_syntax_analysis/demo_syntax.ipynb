{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger, Parser\n",
    "\n",
    "class LtpLanguageAnalysis(object):\n",
    "    def __init__(self, model_dir=\"/home/xxx/ltp-3.4.0/ltp_data/\"):\n",
    "        self.segmentor = Segmentor()\n",
    "        self.segmentor.load(os.path.join(model_dir, \"cws.model\"))\n",
    "        self.postagger = Postagger()\n",
    "        self.postagger.load(os.path.join(model_dir, \"pos.model\"))\n",
    "        self.parser = Parser()\n",
    "        self.parser.load(os.path.join(model_dir, \"parser.model\"))\n",
    "\n",
    "    def analyze(self, text):\n",
    "        # 分词\n",
    "        words = self.segmentor.segment(text)\n",
    "        print '\\t'.join(words)\n",
    "\n",
    "        # 词性标注\n",
    "        postags = self.postagger.postag(words)\n",
    "        print '\\t'.join(postags)\n",
    "\n",
    "        # 句法分析\n",
    "        arcs = self.parser.parse(words, postags)\n",
    "        print \"\\t\".join(\"%d:%s\" % (arc.head, arc.relation) for arc in arcs)\n",
    "\n",
    "    def release_model(self):\n",
    "        # 释放模型\n",
    "        self.segmentor.release()\n",
    "        self.postagger.release()\n",
    "        self.parser.release()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ltp = LtpLanguageAnalysis()\n",
    "    ltp.analyze(\"元芳你怎么看\")\n",
    "    ltp.release_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading https://github.com/hankcs/HanLP/releases/download/v1.7.5/hanlp-1.7.5-release.zip to /Users/sunhongchao/anaconda3/envs/tf_base/lib/python3.7/site-packages/pyhanlp/static/hanlp-1.7.5-release.zip\n100.00%, 1 MB, 855 KB/s, ETA 0 min 0 s\nDownloading http://predator.hankcs.com/data-for-1.7.5.zip to /Users/sunhongchao/anaconda3/envs/tf_base/lib/python3.7/site-packages/pyhanlp/static/data-for-1.7.5.zip\n12.43%, 79 MB, 212 KB/s, ETA 44 min 52 s"
    }
   ],
   "source": [
    "from pyhanlp import HanLP\n",
    "s = '会议宣布了首批资深院士名单'\n",
    "dp = HanLP.parseDependency(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}