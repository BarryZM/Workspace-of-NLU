#!/usr/bin/python3# -*- coding: utf-8 -*-# @Time    : 2019-02-20 22:14# @Author  : apollo2mars# @File    : check_data.py# @Contact : apollo2mars@gmail.com# @Desc    :import os, sysimport collectionsimport math"""root path"""abs_path = os.path.abspath(os.path.dirname(__file__))base_dir = abs_path[:abs_path.find("NLU-AI-SPEAKER") + len("NLU-AI-SPEAKER")]sys.path.append(base_dir)from utils.build_model import *from utils.data_visualization import *def check_spam_line(input_data:list):	print(len(input_data))	for line in input_data:		if len(line.strip()) == 0:			print(line)def check_labels(input_data):	"""	View the number of tag	:param input_data:	:return:	"""	set_label = set()	list_label = []	for item in input_data:		tmp_label = item.split('\t')[1].strip('\n')		set_label.add(tmp_label)		list_label.append(tmp_label)	print('all tag number is ', len(set_label))	print('all tag set is ', set_label)	print('tags and its number is ', collections.Counter(list_label))	read_list_and_draw_pie(collections.Counter(list_label).most_common())def check_labels_for_dict(input_dict:dict):	"""	View the number of tag	:param input_data:	:return:	"""	set_label = set()	list_label = []	for key, value in input_dict.items():		text = key.split('\t')[0]		label = key.split('\t')[1]		set_label.add(label)		while value > 0:			list_label.append(label)			value -= 1	print('all tag number is ', len(set_label))	print('all tag set is ', set_label)	print('tags and its number is ', collections.Counter(list_label))	read_list_and_draw_pie(collections.Counter(list_label).most_common())def check_overlap(data1, data2):	df_1 = pd.read_csv(data1, sep='\t', names=["X", 'y'])	df_2 = pd.read_csv(data2, sep='\t', names=["X", 'y'])	set_1 = set()	for i, row in df_1.iterrows():		set_1.add(row['y'])	print(len(set_1))	print(set_1)	set_2 = set()	for i, row in df_2.iterrows():		set_2.add(row['y'])	print(len(set_2))	print(set_2)	print(set_2 - set_1)def check_multi_label_data(input_data):	"""	:param input_data:	:return:	"""	dict = {}	count = 0	for item in input_data:		text = item.split('\t')[0].strip()		current_label = item.split('\t')[1].strip()		if dict.get(text) is None:			dict[text] = current_label		else:			old_label = dict.get(text)			if old_label != current_label:				print("text is {}, current label is {}, old label is {}".format(text, current_label, old_label))				print(item)				count += 1				print("="*30)	print(count)	return countdef use_new_data_correct_old_data(new_data, old_data):	return_list = []	count = 0	for item_old in old_data:		old_text = item_old.split('\t')[0].strip()		old_label = item_old.split('\t')[1].strip()		"""correct label"""		for item_new in new_data:			new_text = item_new.split('\t')[0].strip()			if old_text == new_text:  # 话术相同				new_label = item_new.split('\t')[1].strip()				if new_label != old_label:  # label 不同					count += 1					print("count", count)					print("item new", item_new)					print("item old", item_old)					break		return_list.append(old_text + '\t' + old_label + '\n')	write_list_to_file("train_data_after_check.txt", return_list)	print(count)	return countdef use_new_data_correct_old_data_by_dict(new_data, old_data):	"""	too slow	should change to dict iterator	:param new_data:	:param old_data:	:return:	"""	return_list = []	count = 0	for item_old in old_data:		old_text = item_old.split('\t')[0].strip()		old_label = item_old.split('\t')[1].strip()		"""correct label"""		for item_new in new_data:			new_text = item_new.split('\t')[0].strip()			if old_text == new_text:  # 话术相同				new_label = item_new.split('\t')[1].strip()				if new_label != old_label:  # label 不同					count += 1					print("count", count)					print("item new", item_new)					print("item old", item_old)					break		return_list.append(old_text + '\t' + old_label + '\n')	print(count)	return countdef draw_len_of_corpus(input_data:list):	import matplotlib.pyplot as plt	tmp_list = [len(item) for item in input_data]	plt.plot(tmp_list)	plt.ylabel('length of input data')	plt.show()	tmp_list = [len(item) for item in input_data]	plt.plot(sorted(tmp_list))	plt.ylabel('length of input data')	plt.show()	count = 0	for item in tmp_list:		if item > 30:			count += 1	print(count)def max_len_of_corpus(input_data:list):	"""	max length of corpus list	:param input_data:	:return:	"""	tmp_list = [len(item) for item in input_data]	max_value = max(tmp_list)	index_max_value = tmp_list.index(max_value)	print(max_value)	print(index_max_value)def data_enhance():	passdef downsampling(input_dict:dict):	for key, value in input_dict.items():		new_value = math.ceil(math.log(value)) + 1  # 以e为底数		input_dict[key] = new_value	print('sample number after down sampling', sum(input_dict.values()))	return input_dictdef list_to_dict(input_list:list):	_dict = {}	for item in input_list:		_dict[item[0]] = item[1]	return _dictdef dict_to_list(input_dict:dict):	r_list = []	for key, value in input_dict.items():		while value > 0:			r_list.append(key)	return r_listdef sort_dict(input:list):	"""	deduplication	:param input:	:return:	"""	dict = {}	for item in input:		if dict.get(item) is None:			dict[item] = 1		else:			dict[item] = dict[item] + 1	# print(dict)	dict_sort_value = sorted(dict.items(), key=lambda d:d[1], reverse=False)	# print("\n\n sample number after deduplication is ", len(dict_sort_value))	count = 0	for item in dict.values():		if item > 4:			count += 1	print(count)  # 709 个长度超过5的样本	return list_to_dict(dict_sort_value)if __name__ == '__main__':	input_data = open_file(base_dir + '/data/THUCnews/test-simple.txt').readlines()	check_spam_line(input_data)	print('all sample number is ', len(input_data))	"""	check tag error	"""	# check_multi_label_data(input_data)	# 当前最新数据依旧存在标注不一致的问题！！！	"""	delete sample which longer than 30	"""	"""	check tags and its number	"""	# check_labels(input_data)	"""	sort dict	"""	# dict_sort_value = sort_dict(input_data)	"""	check the same sample and 	"""	"""	Downsampling in big class	"""	# dict_downsampling = downsampling(dict_sort_value)	# print(check_labels_for_dict(dict_downsampling))	# print(sort_dict(dict_downsampling))	"""	Oversampling in small class	"""	# check_labels(input_data)	# check_labels(old_data)	#	# error_count = check_multi_label_data(input_data)	# if error_count is not 0:	# 	print("input data has multi-label for one test")	# else:	# 	use_new_data_correct_old_data(input_data, old_data=old_data)